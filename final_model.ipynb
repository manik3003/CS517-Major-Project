{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC4SaVi7t7MI",
        "outputId": "616e680b-0291-4785-b14e-0e4e88408ff8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.134-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.134-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.134 ultralytics-thop-2.0.14\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.6.0+cu124)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "!pip install transformers\n",
        "!pip install torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhT255VSz0Xj",
        "outputId": "9ee5da70-633e-48fe-e3ec-19d77a432bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET.zip'\n",
        "\n",
        "zip_dir = os.path.dirname(zip_path)\n",
        "zip_name = os.path.splitext(os.path.basename(zip_path))[0]\n",
        "extract_folder = os.path.join(zip_dir, f\"{zip_name}_unzipped\")\n",
        "\n",
        "# Step 4: Create output folder if it doesn't exist\n",
        "os.makedirs(extract_folder, exist_ok=True)\n",
        "\n",
        "# Step 5: Extract ZIP\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_folder)\n",
        "\n",
        "print(f\"Unzipped successfully to: {extract_folder}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-qG9RqtuKYY",
        "outputId": "f73f48a2-573b-4dd4-9176-e0d356039b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Unzipped successfully to: /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import os\n",
        "import json\n",
        "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# === Paths ===\n",
        "image_dir = \"/content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750\"\n",
        "yolo_model_path = \"/content/drive/MyDrive/Dehaldo/best_yolov8s.pt\"\n",
        "output_dir = \"/content/drive/MyDrive/Dehaldo/OCR_OUTPUTS\"\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# === Load YOLOv8 model ===\n",
        "yolo_model = YOLO(yolo_model_path)\n",
        "\n",
        "# === Load TrOCR model and processor ===\n",
        "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-stage1\")\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-stage1\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# === Get image filenames and select 10% from start + 10% from end ===\n",
        "all_images = sorted([f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "num_total = len(all_images)\n",
        "\n",
        "first_10_percent = all_images[:int(num_total * 0.1)]\n",
        "last_10_percent = all_images[-int(num_total * 0.1):]\n",
        "selected_images = first_10_percent + last_10_percent\n",
        "\n",
        "print(f\"Processing {len(selected_images)} images out of {num_total} (10% from start + 10% from end)\")\n",
        "\n",
        "# === Process each selected image ===\n",
        "for img_name in selected_images:\n",
        "    image_path = os.path.join(image_dir, img_name)\n",
        "    try:\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load {image_path}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Run YOLOv8 on image\n",
        "    results = yolo_model(image_path)\n",
        "    boxes = results[0].boxes.xyxy.cpu().numpy()  # x1, y1, x2, y2\n",
        "    boxes = [list(map(int, box)) for box in boxes]\n",
        "\n",
        "    result_list = []\n",
        "\n",
        "    for box in boxes:\n",
        "        x1, y1, x2, y2 = box\n",
        "        cropped = image.crop((x1, y1, x2, y2))\n",
        "\n",
        "        # Preprocess and predict\n",
        "        pixel_values = processor(images=cropped, return_tensors=\"pt\").pixel_values.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            generated_ids = model.generate(pixel_values)\n",
        "            text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "        result_list.append({\n",
        "            \"box\": [x1, y1, x2, y2],\n",
        "            \"text\": text\n",
        "        })\n",
        "\n",
        "    # Save result to JSON file\n",
        "    json_filename = os.path.splitext(img_name)[0] + \".json\"\n",
        "    json_path = os.path.join(output_dir, json_filename)\n",
        "    with open(json_path, \"w\") as f:\n",
        "        json.dump({image_path: result_list}, f, indent=4)\n",
        "\n",
        "    print(f\"Saved: {json_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThT9-eW5vHqm",
        "outputId": "59b53d2a-751d-482e-8fa5-229dbf64bfd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"encoder_stride\": 16,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"image_size\": 384,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"model_type\": \"vit\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_channels\": 3,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"patch_size\": 16,\n",
            "  \"pooler_act\": \"tanh\",\n",
            "  \"pooler_output_size\": 768,\n",
            "  \"qkv_bias\": false,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.51.3\"\n",
            "}\n",
            "\n",
            "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"relu\",\n",
            "  \"add_cross_attention\": true,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"cross_attention_hidden_size\": 768,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 12,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_decoder\": true,\n",
            "  \"layernorm_embedding\": false,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"trocr\",\n",
            "  \"pad_token_id\": 1,\n",
            "  \"scale_embedding\": true,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": false,\n",
            "  \"use_learned_position_embeddings\": false,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-stage1 and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 150 images out of 750 (10% from start + 10% from end)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_1.jpg: 640x480 21 handwrittens, 12.8ms\n",
            "Speed: 3.2ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_1.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_10.jpg: 640x480 24 handwrittens, 7.0ms\n",
            "Speed: 3.1ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_10.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_100.jpg: 640x480 20 handwrittens, 6.9ms\n",
            "Speed: 3.0ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_100.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_101.jpg: 640x480 20 handwrittens, 6.9ms\n",
            "Speed: 3.2ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_101.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_102.jpg: 640x480 28 handwrittens, 12.6ms\n",
            "Speed: 5.4ms preprocess, 12.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_102.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_103.jpg: 640x480 22 handwrittens, 7.2ms\n",
            "Speed: 3.2ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_103.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_104.jpg: 640x480 23 handwrittens, 7.0ms\n",
            "Speed: 3.2ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_104.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_105.jpg: 640x480 25 handwrittens, 12.7ms\n",
            "Speed: 4.4ms preprocess, 12.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_105.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_106.jpg: 640x480 22 handwrittens, 8.4ms\n",
            "Speed: 3.4ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_106.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_108.jpg: 640x480 21 handwrittens, 7.3ms\n",
            "Speed: 3.2ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_108.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_11.jpg: 640x480 23 handwrittens, 7.0ms\n",
            "Speed: 3.0ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_11.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_110.jpg: 640x480 26 handwrittens, 7.6ms\n",
            "Speed: 3.3ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_110.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_111.jpg: 640x480 20 handwrittens, 7.3ms\n",
            "Speed: 3.1ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_111.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_113.jpg: 640x480 22 handwrittens, 7.5ms\n",
            "Speed: 3.5ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_113.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_114.jpg: 640x480 29 handwrittens, 7.5ms\n",
            "Speed: 3.3ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_114.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_115.jpg: 640x480 25 handwrittens, 7.2ms\n",
            "Speed: 3.1ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_115.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_116.jpg: 640x480 23 handwrittens, 7.5ms\n",
            "Speed: 3.1ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_116.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_117.jpg: 640x480 21 handwrittens, 9.5ms\n",
            "Speed: 3.2ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_117.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_118.jpg: 640x480 25 handwrittens, 8.7ms\n",
            "Speed: 4.6ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_118.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_119.jpg: 640x480 20 handwrittens, 7.5ms\n",
            "Speed: 3.1ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_119.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_12.jpg: 640x480 21 handwrittens, 8.3ms\n",
            "Speed: 3.4ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_12.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_120.jpg: 640x480 22 handwrittens, 7.5ms\n",
            "Speed: 3.2ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_120.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_121.jpg: 640x480 21 handwrittens, 8.5ms\n",
            "Speed: 3.1ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_121.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_122.jpg: 640x480 22 handwrittens, 10.9ms\n",
            "Speed: 4.4ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_122.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_123.jpg: 640x480 20 handwrittens, 8.0ms\n",
            "Speed: 3.3ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_123.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_124.jpg: 640x480 20 handwrittens, 8.7ms\n",
            "Speed: 5.8ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_124.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_125.jpg: 640x480 21 handwrittens, 7.6ms\n",
            "Speed: 3.2ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_125.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_126.jpg: 640x480 22 handwrittens, 7.6ms\n",
            "Speed: 3.3ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_126.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_128.jpg: 640x480 24 handwrittens, 7.0ms\n",
            "Speed: 3.0ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_128.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_129.jpg: 640x480 21 handwrittens, 7.0ms\n",
            "Speed: 3.2ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_129.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_13.jpg: 640x480 21 handwrittens, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_13.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_130.jpg: 640x480 23 handwrittens, 8.1ms\n",
            "Speed: 3.2ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_130.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_131.jpg: 640x480 22 handwrittens, 9.8ms\n",
            "Speed: 3.2ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_131.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_132.jpg: 640x480 21 handwrittens, 7.4ms\n",
            "Speed: 3.2ms preprocess, 7.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_132.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_133.jpg: 640x480 20 handwrittens, 9.5ms\n",
            "Speed: 3.1ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_133.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_134.jpg: 640x480 22 handwrittens, 7.6ms\n",
            "Speed: 3.2ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_134.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_135.jpg: 640x480 20 handwrittens, 7.3ms\n",
            "Speed: 3.4ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_135.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_136.jpg: 640x480 20 handwrittens, 12.6ms\n",
            "Speed: 4.4ms preprocess, 12.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_136.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_137.jpg: 640x480 21 handwrittens, 7.0ms\n",
            "Speed: 3.0ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_137.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_138.jpg: 640x480 22 handwrittens, 7.2ms\n",
            "Speed: 3.2ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_138.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_139.jpg: 640x480 22 handwrittens, 7.5ms\n",
            "Speed: 3.3ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_139.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_14.jpg: 640x480 26 handwrittens, 7.0ms\n",
            "Speed: 3.0ms preprocess, 7.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_14.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_140.jpg: 640x480 20 handwrittens, 9.7ms\n",
            "Speed: 4.6ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_140.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_141.jpg: 640x480 24 handwrittens, 7.1ms\n",
            "Speed: 3.1ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_141.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_142.jpg: 640x480 25 handwrittens, 8.6ms\n",
            "Speed: 4.5ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_142.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_143.jpg: 640x480 22 handwrittens, 7.2ms\n",
            "Speed: 3.2ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_143.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_144.jpg: 640x480 20 handwrittens, 7.7ms\n",
            "Speed: 3.3ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_144.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_145.jpg: 640x480 22 handwrittens, 12.7ms\n",
            "Speed: 5.0ms preprocess, 12.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_145.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_146.jpg: 640x480 20 handwrittens, 7.5ms\n",
            "Speed: 3.3ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_146.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_147.jpg: 640x480 23 handwrittens, 8.0ms\n",
            "Speed: 3.6ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_147.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_148.jpg: 640x480 21 handwrittens, 7.2ms\n",
            "Speed: 3.1ms preprocess, 7.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_148.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_149.jpg: 640x480 21 handwrittens, 7.4ms\n",
            "Speed: 3.3ms preprocess, 7.4ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_149.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_15.jpg: 640x480 23 handwrittens, 14.5ms\n",
            "Speed: 4.7ms preprocess, 14.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_15.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_150.jpg: 640x480 25 handwrittens, 7.3ms\n",
            "Speed: 3.2ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_150.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_151.jpg: 640x480 25 handwrittens, 8.0ms\n",
            "Speed: 3.0ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_151.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_152.jpg: 640x480 20 handwrittens, 7.1ms\n",
            "Speed: 3.1ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_152.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_153.jpg: 640x480 19 handwrittens, 7.7ms\n",
            "Speed: 3.1ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_153.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_154.jpg: 640x480 22 handwrittens, 23.4ms\n",
            "Speed: 9.3ms preprocess, 23.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_154.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_155.jpg: 640x480 21 handwrittens, 7.2ms\n",
            "Speed: 3.0ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_155.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_156.jpg: 640x480 22 handwrittens, 13.0ms\n",
            "Speed: 4.4ms preprocess, 13.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_156.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_158.jpg: 640x480 20 handwrittens, 7.0ms\n",
            "Speed: 3.0ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_158.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_16.jpg: 640x480 21 handwrittens, 8.1ms\n",
            "Speed: 3.3ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_16.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_161.jpg: 640x480 20 handwrittens, 7.1ms\n",
            "Speed: 3.0ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_161.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_162.jpg: 640x480 24 handwrittens, 7.1ms\n",
            "Speed: 3.0ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_162.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_163.jpg: 640x480 23 handwrittens, 7.2ms\n",
            "Speed: 3.2ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_163.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_164.jpg: 640x480 23 handwrittens, 7.4ms\n",
            "Speed: 3.1ms preprocess, 7.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_164.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_165.jpg: 640x480 23 handwrittens, 7.2ms\n",
            "Speed: 3.1ms preprocess, 7.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_165.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_168.jpg: 640x480 22 handwrittens, 8.7ms\n",
            "Speed: 4.3ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_168.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_169.jpg: 640x480 21 handwrittens, 7.2ms\n",
            "Speed: 3.0ms preprocess, 7.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_169.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_17.jpg: 640x480 21 handwrittens, 7.4ms\n",
            "Speed: 3.2ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_17.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_170.jpg: 640x480 26 handwrittens, 7.3ms\n",
            "Speed: 3.1ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_170.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_171.jpg: 640x480 21 handwrittens, 12.4ms\n",
            "Speed: 4.9ms preprocess, 12.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_171.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_172.jpg: 640x480 21 handwrittens, 7.4ms\n",
            "Speed: 3.1ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_172.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_173.jpg: 640x480 22 handwrittens, 15.3ms\n",
            "Speed: 4.3ms preprocess, 15.3ms inference, 6.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_173.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/MIT_174.jpg: 640x480 24 handwrittens, 7.2ms\n",
            "Speed: 3.0ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/MIT_174.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_810.jpg: 640x480 27 handwrittens, 7.6ms\n",
            "Speed: 3.2ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_810.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_811.jpg: 640x480 25 handwrittens, 6.9ms\n",
            "Speed: 3.1ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_811.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_812.jpg: 640x480 22 handwrittens, 7.3ms\n",
            "Speed: 3.1ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_812.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_813.jpg: 640x480 22 handwrittens, 7.1ms\n",
            "Speed: 3.3ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_813.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_814.jpg: 640x480 24 handwrittens, 9.6ms\n",
            "Speed: 4.9ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_814.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_815.jpg: 640x480 24 handwrittens, 7.1ms\n",
            "Speed: 3.2ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_815.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_816.jpg: 640x480 25 handwrittens, 7.0ms\n",
            "Speed: 3.1ms preprocess, 7.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_816.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_817.jpg: 640x480 23 handwrittens, 9.3ms\n",
            "Speed: 4.5ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_817.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_818.jpg: 640x480 23 handwrittens, 7.4ms\n",
            "Speed: 3.1ms preprocess, 7.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_818.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_819.jpg: 640x480 23 handwrittens, 7.4ms\n",
            "Speed: 3.1ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_819.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_820.jpg: 640x480 23 handwrittens, 14.0ms\n",
            "Speed: 9.0ms preprocess, 14.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_820.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_821.jpg: 640x480 26 handwrittens, 25.5ms\n",
            "Speed: 10.7ms preprocess, 25.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_821.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_822.jpg: 640x480 27 handwrittens, 10.1ms\n",
            "Speed: 4.4ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_822.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_823.jpg: 640x480 25 handwrittens, 11.6ms\n",
            "Speed: 3.6ms preprocess, 11.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_823.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_824.jpg: 640x480 26 handwrittens, 16.8ms\n",
            "Speed: 4.4ms preprocess, 16.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_824.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_825.jpg: 640x480 21 handwrittens, 7.2ms\n",
            "Speed: 3.3ms preprocess, 7.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_825.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_826.jpg: 640x480 28 handwrittens, 7.1ms\n",
            "Speed: 3.1ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_826.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_827.jpg: 640x480 25 handwrittens, 7.1ms\n",
            "Speed: 3.2ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_827.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_828.jpg: 640x480 21 handwrittens, 7.3ms\n",
            "Speed: 3.1ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_828.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_829.jpg: 640x480 26 handwrittens, 7.3ms\n",
            "Speed: 3.2ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_829.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_830.jpg: 640x480 22 handwrittens, 7.0ms\n",
            "Speed: 3.1ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_830.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_831.jpg: 640x480 24 handwrittens, 7.4ms\n",
            "Speed: 3.3ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_831.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_832.jpg: 640x480 22 handwrittens, 7.3ms\n",
            "Speed: 3.2ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_832.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_833.jpg: 640x480 23 handwrittens, 13.3ms\n",
            "Speed: 4.4ms preprocess, 13.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_833.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_834.jpg: 640x480 20 handwrittens, 7.3ms\n",
            "Speed: 3.1ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_834.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_835.jpg: 640x480 22 handwrittens, 7.4ms\n",
            "Speed: 3.2ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_835.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_836.jpg: 640x480 23 handwrittens, 7.3ms\n",
            "Speed: 3.1ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_836.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_837.jpg: 640x480 22 handwrittens, 6.8ms\n",
            "Speed: 3.1ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_837.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_838.jpg: 640x480 21 handwrittens, 7.2ms\n",
            "Speed: 3.2ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_838.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_839.jpg: 640x480 22 handwrittens, 8.8ms\n",
            "Speed: 3.2ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_839.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_840.jpg: 640x480 22 handwrittens, 14.6ms\n",
            "Speed: 4.4ms preprocess, 14.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_840.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_845.jpg: 640x480 20 handwrittens, 7.3ms\n",
            "Speed: 3.1ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_845.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_846.jpg: 640x480 21 handwrittens, 7.2ms\n",
            "Speed: 3.0ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_846.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_847.jpg: 640x480 29 handwrittens, 7.1ms\n",
            "Speed: 3.1ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_847.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_849.jpg: 640x480 20 handwrittens, 12.4ms\n",
            "Speed: 3.3ms preprocess, 12.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_849.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_850.jpg: 640x480 21 handwrittens, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_850.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_851.jpg: 640x480 22 handwrittens, 7.4ms\n",
            "Speed: 3.2ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_851.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_853.jpg: 640x480 24 handwrittens, 7.9ms\n",
            "Speed: 3.1ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_853.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_854.jpg: 640x480 26 handwrittens, 7.5ms\n",
            "Speed: 3.1ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_854.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_856.jpg: 640x480 22 handwrittens, 7.2ms\n",
            "Speed: 3.1ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_856.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_857.jpg: 640x480 21 handwrittens, 9.3ms\n",
            "Speed: 3.1ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_857.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_859.jpg: 640x480 24 handwrittens, 7.0ms\n",
            "Speed: 3.2ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_859.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_861.jpg: 640x480 27 handwrittens, 7.0ms\n",
            "Speed: 3.1ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_861.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_862.jpg: 640x480 23 handwrittens, 9.8ms\n",
            "Speed: 4.7ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_862.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_863.jpg: 640x480 22 handwrittens, 7.2ms\n",
            "Speed: 3.2ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_863.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_865.jpg: 640x480 26 handwrittens, 7.1ms\n",
            "Speed: 3.1ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_865.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_866.jpg: 640x480 24 handwrittens, 11.0ms\n",
            "Speed: 4.8ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_866.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_868.jpg: 640x480 23 handwrittens, 7.4ms\n",
            "Speed: 3.2ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_868.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_869.jpg: 640x480 22 handwrittens, 7.0ms\n",
            "Speed: 3.1ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_869.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_870.jpg: 640x480 25 handwrittens, 7.4ms\n",
            "Speed: 3.2ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_870.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_871.jpg: 640x480 25 handwrittens, 7.3ms\n",
            "Speed: 3.2ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_871.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_872.jpg: 640x480 23 handwrittens, 7.0ms\n",
            "Speed: 3.1ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_872.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_873.jpg: 640x480 23 handwrittens, 7.6ms\n",
            "Speed: 3.2ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_873.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_874.jpg: 640x480 25 handwrittens, 7.0ms\n",
            "Speed: 3.1ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_874.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_875.jpg: 640x480 21 handwrittens, 12.6ms\n",
            "Speed: 4.4ms preprocess, 12.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_875.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_876.jpg: 640x480 24 handwrittens, 9.8ms\n",
            "Speed: 3.1ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_876.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_878.jpg: 640x480 22 handwrittens, 9.1ms\n",
            "Speed: 3.2ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_878.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_879.jpg: 640x480 21 handwrittens, 7.3ms\n",
            "Speed: 3.1ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_879.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_880.jpg: 640x480 22 handwrittens, 7.8ms\n",
            "Speed: 3.4ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_880.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_881.jpg: 640x480 21 handwrittens, 12.6ms\n",
            "Speed: 4.7ms preprocess, 12.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_881.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_883.jpg: 640x480 26 handwrittens, 6.9ms\n",
            "Speed: 3.1ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_883.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_886.jpg: 640x480 22 handwrittens, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_886.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_887.jpg: 640x480 22 handwrittens, 8.2ms\n",
            "Speed: 3.5ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_887.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_888.jpg: 640x480 22 handwrittens, 7.3ms\n",
            "Speed: 3.1ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_888.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_895.jpg: 640x480 22 handwrittens, 7.6ms\n",
            "Speed: 3.1ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_895.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_896.jpg: 640x480 23 handwrittens, 6.8ms\n",
            "Speed: 3.0ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_896.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_898.jpg: 640x480 23 handwrittens, 7.5ms\n",
            "Speed: 3.2ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_898.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_899.jpg: 640x480 21 handwrittens, 8.3ms\n",
            "Speed: 3.5ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_899.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_900.jpg: 640x480 23 handwrittens, 7.5ms\n",
            "Speed: 3.3ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_900.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_901.jpg: 640x480 23 handwrittens, 11.1ms\n",
            "Speed: 4.5ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_901.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_902.jpg: 640x480 24 handwrittens, 7.1ms\n",
            "Speed: 3.2ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_902.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_903.jpg: 640x480 21 handwrittens, 7.1ms\n",
            "Speed: 3.1ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_903.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_904.jpg: 640x480 20 handwrittens, 7.2ms\n",
            "Speed: 3.1ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_904.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_905.jpg: 640x480 22 handwrittens, 7.2ms\n",
            "Speed: 3.1ms preprocess, 7.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_905.json\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/IMAGES_750/VIT_906.jpg: 640x480 22 handwrittens, 9.7ms\n",
            "Speed: 4.5ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Saved: /content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/VIT_906.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpXOqyHZvu0m",
        "outputId": "055a236c-0594-4685-96f9-2546019ccd02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jiwer\n",
            "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-3.1.0 rapidfuzz-3.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from difflib import SequenceMatcher\n",
        "from glob import glob\n",
        "\n",
        "# --- Utility Functions ---\n",
        "def iou(boxA, boxB):\n",
        "    xA = max(boxA[0], boxB[0])\n",
        "    yA = max(boxA[1], boxB[1])\n",
        "    xB = min(boxA[2], boxB[2])\n",
        "    yB = min(boxA[3], boxB[3])\n",
        "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
        "    if interArea == 0:\n",
        "        return 0.0\n",
        "    areaA = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
        "    areaB = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
        "    return interArea / float(areaA + areaB - interArea)\n",
        "\n",
        "def similarity(a, b):\n",
        "    return SequenceMatcher(None, a, b).ratio()\n",
        "\n",
        "# --- Paths ---\n",
        "pred_dir = \"/content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/\"\n",
        "gt_dir = \"/content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/LABELS_750\"\n",
        "output_dir = \"/content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Get all image names\n",
        "image_names = sorted([os.path.basename(f).replace(\".json\", \"\") for f in glob(os.path.join(gt_dir, \"*.json\"))])\n",
        "n_total = len(image_names)\n",
        "first_10_percent = image_names[:int(n_total * 0.1)]\n",
        "last_10_percent = image_names[int(n_total * 0.9):]\n",
        "\n",
        "for name in first_10_percent + last_10_percent:\n",
        "    pred_file = os.path.join(pred_dir, name + \".json\")\n",
        "    gt_file = os.path.join(gt_dir, name + \".json\")\n",
        "\n",
        "    if not os.path.exists(pred_file) or not os.path.exists(gt_file):\n",
        "        print(f\"Skipping {name}: Missing file(s)\")\n",
        "        continue\n",
        "\n",
        "    with open(pred_file) as f:\n",
        "        pred_json = json.load(f)\n",
        "    with open(gt_file) as f:\n",
        "        gt_entries = json.load(f)\n",
        "\n",
        "    # Extract predictions (TrOCR format)\n",
        "    pred_entries = list(pred_json.values())[0] if isinstance(pred_json, dict) else pred_json\n",
        "\n",
        "    if isinstance(pred_entries[0], str):\n",
        "        pred_entries = [json.loads(p.replace(\"'\", '\"')) for p in pred_entries]\n",
        "\n",
        "    used_pred_indices = set()\n",
        "    matched_output = []\n",
        "\n",
        "    for gt in gt_entries:\n",
        "        gt_box = gt[\"Coordinate\"]\n",
        "        gt_text = gt[\"Field value\"].strip()\n",
        "        field_name = gt.get(\"Field name\", \"\")  # If field name exists\n",
        "\n",
        "        best_match, best_score, best_idx = \"\", 0, -1\n",
        "\n",
        "        for i, pred in enumerate(pred_entries):\n",
        "            if i in used_pred_indices:\n",
        "                continue\n",
        "            pred_box, pred_text = pred[\"box\"], pred[\"text\"]\n",
        "\n",
        "            if iou(gt_box, pred_box) > 0.3:\n",
        "                sim = similarity(gt_text.lower(), pred_text.strip().lower())\n",
        "                if sim > best_score:\n",
        "                    best_score, best_match, best_idx = sim, pred_text.strip(), i\n",
        "\n",
        "        if best_idx != -1:\n",
        "            used_pred_indices.add(best_idx)\n",
        "            matched_output.append({\n",
        "                \"field_name\": field_name,\n",
        "                \"ground_truth\": gt_text,\n",
        "                \"prediction\": best_match\n",
        "            })\n",
        "        else:\n",
        "            matched_output.append({\n",
        "                \"field_name\": field_name,\n",
        "                \"ground_truth\": gt_text,\n",
        "                \"prediction\": \"\"\n",
        "            })\n",
        "\n",
        "    # Save to individual JSON file\n",
        "    out_path = os.path.join(output_dir, name + \"_matched.json\")\n",
        "    with open(out_path, \"w\") as f:\n",
        "        json.dump(matched_output, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"Saved matched file: {out_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Apj3miub1tCT",
        "outputId": "eeea4bc8-d811-40bf-99c4-e71126c8390d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_1_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_10_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_100_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_101_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_102_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_103_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_104_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_105_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_106_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_108_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_11_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_110_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_111_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_113_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_114_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_115_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_116_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_117_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_118_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_119_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_12_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_120_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_121_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_122_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_123_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_124_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_125_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_126_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_128_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_129_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_13_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_130_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_131_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_132_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_133_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_134_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_135_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_136_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_137_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_138_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_139_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_14_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_140_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_141_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_142_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_143_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_144_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_145_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_146_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_147_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_148_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_149_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_15_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_150_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_151_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_152_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_153_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_154_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_155_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_156_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_158_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_16_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_161_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_162_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_163_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_164_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_165_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_168_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_169_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_17_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_170_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_171_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_172_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_173_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_174_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_810_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_811_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_812_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_813_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_814_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_815_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_816_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_817_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_818_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_819_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_820_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_821_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_822_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_823_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_824_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_825_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_826_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_827_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_828_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_829_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_830_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_831_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_832_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_833_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_834_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_835_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_836_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_837_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_838_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_839_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_840_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_845_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_846_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_847_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_849_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_850_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_851_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_853_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_854_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_856_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_857_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_859_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_861_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_862_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_863_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_865_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_866_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_868_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_869_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_870_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_871_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_872_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_873_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_874_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_875_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_876_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_878_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_879_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_880_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_881_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_883_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_886_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_887_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_888_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_895_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_896_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_898_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_899_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_900_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_901_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_902_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_903_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_904_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_905_matched.json\n",
            "Saved matched file: /content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/VIT_906_matched.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import difflib\n",
        "\n",
        "def clean_number_spaces(prediction: str) -> str:\n",
        "    \"\"\"Remove spaces between digits.\"\"\"\n",
        "    return re.sub(r'(?<=\\d)\\s+(?=\\d)', '', prediction)\n",
        "\n",
        "def clean_date_prediction(prediction: str) -> str:\n",
        "    \"\"\"Fix date format: remove spaces and reformat to MM/DD/YYYY.\"\"\"\n",
        "    prediction = prediction.replace(' ', '').replace('|', '1')\n",
        "    match = re.search(r'(\\d{1,2})[^\\d]*(\\d{1,2})[^\\d]*(\\d{4})', prediction)\n",
        "    if match:\n",
        "        return f\"{match.group(1).zfill(2)}/{match.group(2).zfill(2)}/{match.group(3)}\"\n",
        "    return prediction\n",
        "\n",
        "def normalize_fuzzy(prediction: str, valid_list: list) -> str:\n",
        "    \"\"\"Return the closest match from a list using difflib.\"\"\"\n",
        "    cleaned = prediction.strip().replace('.', '').replace('–', '-').capitalize()\n",
        "    match = difflib.get_close_matches(cleaned, valid_list, n=1, cutoff=0.5)\n",
        "    return match[0] if match else prediction\n",
        "\n",
        "def normalize_languages(prediction: str, valid_languages: list) -> str:\n",
        "    \"\"\"Normalize comma-separated language names to the closest valid ones, preserving order.\"\"\"\n",
        "    langs = re.split(r'[;,]', prediction)\n",
        "    seen = set()\n",
        "    normalized = []\n",
        "\n",
        "    for lang in langs:\n",
        "        cleaned = lang.strip().capitalize()\n",
        "        match = difflib.get_close_matches(cleaned, valid_languages, n=1, cutoff=0.4)\n",
        "        corrected = match[0] if match else cleaned\n",
        "        if corrected not in seen:\n",
        "            normalized.append(corrected)\n",
        "            seen.add(corrected)\n",
        "\n",
        "    return ', '.join(normalized)\n",
        "\n",
        "def normalize_blood_group(prediction: str) -> str:\n",
        "    \"\"\"Normalize blood group, handling spaces, 't' or 'f' in front of letters, and + or - signs.\"\"\"\n",
        "    prediction = prediction.strip().replace(\" \", \"\").replace(\".\", \"\")  # Remove spaces and periods\n",
        "\n",
        "    # Handle cases where 't' or 'f' is in front of the blood group letter (e.g., 'tA', 'fA' -> 'A+')\n",
        "    if prediction.lower().startswith(\"t\") or prediction.lower().startswith(\"f\"):\n",
        "        prediction = prediction[1:]  # Remove the 't' or 'f'\n",
        "\n",
        "    # Handle cases like \"At\" or \"At.\" by converting to \"A+\"\n",
        "    if prediction.lower() == \"at\" or prediction.lower() == \"at.\":\n",
        "        return \"A+\"\n",
        "\n",
        "    # Handle cases like \"fA\" or \"fA.\"\n",
        "    if prediction.lower().startswith(\"a\"):\n",
        "        return \"A+\"\n",
        "    if prediction.lower().startswith(\"b\"):\n",
        "        return \"B+\"\n",
        "    if prediction.lower().startswith(\"ab\"):\n",
        "        return \"AB+\"\n",
        "    if prediction.lower().startswith(\"o\"):\n",
        "        return \"O+\"\n",
        "\n",
        "    # Validate against known blood group options\n",
        "    valid_blood_groups = [\"A+\", \"A-\", \"B+\", \"B-\", \"AB+\", \"AB-\", \"O+\", \"O-\"]\n",
        "    if prediction in valid_blood_groups:\n",
        "        return prediction\n",
        "\n",
        "    return \"Invalid\"  # Return \"Invalid\" if it's not a valid blood group\n",
        "\n",
        "def normalize_nationality(prediction: str) -> str:\n",
        "    \"\"\"Normalize nationality to 'Indian' if found.\"\"\"\n",
        "    if \"indian\" in prediction.lower():\n",
        "        return \"Indian\"\n",
        "    return prediction\n",
        "\n",
        "def clean_pancard(prediction: str) -> str:\n",
        "    \"\"\"Clean and format Pancard number by removing spaces between alphanumeric characters.\"\"\"\n",
        "    return re.sub(r'\\s+', '', prediction)\n",
        "\n",
        "def clean_address(prediction: str) -> str:\n",
        "    \"\"\"Clean and standardize address format.\"\"\"\n",
        "    prediction = prediction.strip()\n",
        "\n",
        "    # Fix variations of \"H. No\" to \"H.No.\"\n",
        "    prediction = re.sub(r'\\bH\\s*\\.\\s*No\\b\\.?', 'H.No.', prediction, flags=re.IGNORECASE)\n",
        "\n",
        "    # Remove space between digits and symbols like '/' (e.g., \"70 / 9kg\" -> \"70/9kg\")\n",
        "    prediction = re.sub(r'(?<=\\d)\\s*/\\s*(?=\\d)', '/', prediction)\n",
        "\n",
        "    # Concatenate numbers split by space (e.g., \"09 2248\" -> \"092248\")\n",
        "    prediction = re.sub(r'(?<=\\d)\\s+(?=\\d)', '', prediction)\n",
        "\n",
        "    # Normalize multiple spaces to single space\n",
        "    prediction = re.sub(r'\\s{2,}', ' ', prediction)\n",
        "\n",
        "    return prediction.strip()\n",
        "\n",
        "\n",
        "\n",
        "def postprocess_predictions(input_path, output_path):\n",
        "    with open(input_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    for entry in data:\n",
        "        field = entry[\"field_name\"].lower()\n",
        "        prediction = entry[\"prediction\"]\n",
        "\n",
        "        if \"dateofbirth\" in field or field == \"date\":\n",
        "            cleaned = clean_date_prediction(prediction)\n",
        "\n",
        "        elif \"qualification\" in field:\n",
        "            cleaned = normalize_fuzzy(prediction, [\n",
        "                \"Graduate\", \"Post-Graduate\", \"Undergraduate\",\n",
        "                \"Diploma\", \"Doctorate\", \"Post-Doctorate\", \"10th Pass\", \"12th Pass\"\n",
        "            ])\n",
        "\n",
        "        elif \"gender\" in field:\n",
        "            cleaned = normalize_fuzzy(prediction, [\"Male\", \"Female\"])\n",
        "\n",
        "        elif \"maritalstatus\" in field:\n",
        "            cleaned = normalize_fuzzy(prediction, [\n",
        "                \"Married\", \"Single\", \"Divorced\", \"Widow\"\n",
        "            ])\n",
        "\n",
        "        elif \"languageknown\" in field:\n",
        "            cleaned = normalize_languages(prediction, [\n",
        "                \"Hindi\", \"English\", \"Gujarati\", \"Marathi\", \"Telugu\",\n",
        "                \"Kannada\", \"Tamil\", \"Punjabi\", \"Bengali\", \"Urdu\"\n",
        "            ])\n",
        "\n",
        "        elif \"bloodgroup\" in field:\n",
        "            cleaned = normalize_blood_group(prediction)\n",
        "\n",
        "        elif \"nationality\" in field:\n",
        "            cleaned = normalize_nationality(prediction)\n",
        "\n",
        "        elif \"pancard\" in field:\n",
        "            cleaned = clean_pancard(prediction)\n",
        "\n",
        "        elif \"presentaddress\" in field or \"permanentaddress\" in field:\n",
        "            cleaned = clean_address(prediction)\n",
        "\n",
        "        else:\n",
        "            cleaned = clean_number_spaces(prediction)\n",
        "\n",
        "        if cleaned == \"Invalid\":\n",
        "            print(f\"Invalid value detected in field '{field}' with prediction '{prediction}'\")\n",
        "\n",
        "        entry[\"prediction\"] = cleaned\n",
        "\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"✅ Cleaned output written to {output_path}\")\n"
      ],
      "metadata": {
        "id": "fTvLuzVe2woo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_json = \"/content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_168_matched.json\"\n",
        "output_json = \"/content/drive/MyDrive/Dehaldo/EVALUATION_MATCHED_RESULTS/MIT_168_matched_cleaned.json\"\n",
        "\n",
        "postprocess_predictions(input_json, output_json)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nV0ENe5V2zGe",
        "outputId": "1901adf3-d059-4e60-9bc4-78d995c75779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'8134149090'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "import difflib\n",
        "from difflib import SequenceMatcher\n",
        "from glob import glob\n",
        "\n",
        "# ---------- UTILITY FUNCTIONS ----------\n",
        "def iou(boxA, boxB):\n",
        "    xA = max(boxA[0], boxB[0])\n",
        "    yA = max(boxA[1], boxB[1])\n",
        "    xB = min(boxA[2], boxB[2])\n",
        "    yB = min(boxA[3], boxB[3])\n",
        "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
        "    if interArea == 0:\n",
        "        return 0.0\n",
        "    areaA = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
        "    areaB = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
        "    return interArea / float(areaA + areaB - interArea)\n",
        "\n",
        "def similarity(a, b):\n",
        "    return SequenceMatcher(None, a, b).ratio()\n",
        "\n",
        "# ---------- POSTPROCESSING ----------\n",
        "def clean_number_spaces(prediction):\n",
        "    return re.sub(r'(?<=\\d)\\s+(?=\\d)', '', prediction)\n",
        "\n",
        "def clean_date_prediction(prediction):\n",
        "    prediction = prediction.replace(' ', '').replace('|', '1')\n",
        "    match = re.search(r'(\\d{1,2})[^\\d]*(\\d{1,2})[^\\d]*(\\d{4})', prediction)\n",
        "    if match:\n",
        "        return f\"{match.group(1).zfill(2)}/{match.group(2).zfill(2)}/{match.group(3)}\"\n",
        "    return prediction\n",
        "\n",
        "def normalize_fuzzy(prediction, valid_list):\n",
        "    cleaned = prediction.strip().replace('.', '').replace('–', '-').capitalize()\n",
        "    match = difflib.get_close_matches(cleaned, valid_list, n=1, cutoff=0.5)\n",
        "    return match[0] if match else prediction\n",
        "\n",
        "def normalize_languages(prediction, valid_languages):\n",
        "    langs = re.split(r'[;,]', prediction)\n",
        "    seen = set()\n",
        "    normalized = []\n",
        "    for lang in langs:\n",
        "        cleaned = lang.strip().capitalize()\n",
        "        match = difflib.get_close_matches(cleaned, valid_languages, n=1, cutoff=0.4)\n",
        "        corrected = match[0] if match else cleaned\n",
        "        if corrected not in seen:\n",
        "            normalized.append(corrected)\n",
        "            seen.add(corrected)\n",
        "    return ', '.join(normalized)\n",
        "\n",
        "def normalize_blood_group(prediction):\n",
        "    prediction = prediction.strip().replace(\" \", \"\").replace(\".\", \"\")\n",
        "    if prediction.lower().startswith((\"t\", \"f\")):\n",
        "        prediction = prediction[1:]\n",
        "    if prediction.lower() == \"at\" or prediction.lower().startswith(\"a\"):\n",
        "        return \"A+\"\n",
        "    if prediction.lower().startswith(\"b\"):\n",
        "        return \"B+\"\n",
        "    if prediction.lower().startswith(\"ab\"):\n",
        "        return \"AB+\"\n",
        "    if prediction.lower().startswith(\"o\"):\n",
        "        return \"O+\"\n",
        "    valid = [\"A+\", \"A-\", \"B+\", \"B-\", \"AB+\", \"AB-\", \"O+\", \"O-\"]\n",
        "    return prediction if prediction in valid else \"Invalid\"\n",
        "\n",
        "def normalize_nationality(prediction):\n",
        "    return \"Indian\" if \"indian\" in prediction.lower() else prediction\n",
        "\n",
        "def clean_pancard(prediction):\n",
        "    return re.sub(r'\\s+', '', prediction)\n",
        "\n",
        "def clean_address(prediction):\n",
        "    prediction = prediction.strip()\n",
        "    prediction = re.sub(r'\\bH\\s*\\.\\s*No\\b\\.?', 'H.No.', prediction, flags=re.IGNORECASE)\n",
        "    prediction = re.sub(r'(?<=\\d)\\s*/\\s*(?=\\d)', '/', prediction)\n",
        "    prediction = re.sub(r'(?<=\\d)\\s+(?=\\d)', '', prediction)\n",
        "    prediction = re.sub(r'\\s{2,}', ' ', prediction)\n",
        "    return prediction.strip()\n",
        "\n",
        "def postprocess(field, prediction):\n",
        "    field = field.lower()\n",
        "    if \"dateofbirth\" in field or field == \"date\":\n",
        "        return clean_date_prediction(prediction)\n",
        "    elif \"qualification\" in field:\n",
        "        return normalize_fuzzy(prediction, [\"Graduate\", \"Post-Graduate\", \"Undergraduate\", \"Diploma\", \"Doctorate\", \"Post-Doctorate\", \"10th Pass\", \"12th Pass\"])\n",
        "    elif \"gender\" in field:\n",
        "        return normalize_fuzzy(prediction, [\"Male\", \"Female\"])\n",
        "    elif \"maritalstatus\" in field:\n",
        "        return normalize_fuzzy(prediction, [\"Married\", \"Single\", \"Divorced\", \"Widow\"])\n",
        "    elif \"languageknown\" in field:\n",
        "        return normalize_languages(prediction, [\"Hindi\", \"English\", \"Gujarati\", \"Marathi\", \"Telugu\", \"Kannada\", \"Tamil\", \"Punjabi\", \"Bengali\", \"Urdu\"])\n",
        "    elif \"bloodgroup\" in field:\n",
        "        return normalize_blood_group(prediction)\n",
        "    elif \"nationality\" in field:\n",
        "        return normalize_nationality(prediction)\n",
        "    elif \"pancard\" in field:\n",
        "        return clean_pancard(prediction)\n",
        "    elif \"presentaddress\" in field or \"permanentaddress\" in field:\n",
        "        return clean_address(prediction)\n",
        "    else:\n",
        "        return clean_number_spaces(prediction)\n",
        "\n",
        "# ---------- MAIN LOGIC ----------\n",
        "pred_dir = \"/content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/\"\n",
        "gt_dir = \"/content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/LABELS_750\"\n",
        "output_dir = \"/content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "image_names = sorted([os.path.basename(f).replace(\".json\", \"\") for f in glob(os.path.join(gt_dir, \"*.json\"))])\n",
        "n_total = len(image_names)\n",
        "first_10_percent = image_names[:int(n_total * 0.1)]\n",
        "last_10_percent = image_names[int(n_total * 0.9):]\n",
        "\n",
        "for name in first_10_percent + last_10_percent:\n",
        "    pred_file = os.path.join(pred_dir, name + \".json\")\n",
        "    gt_file = os.path.join(gt_dir, name + \".json\")\n",
        "\n",
        "    if not os.path.exists(pred_file) or not os.path.exists(gt_file):\n",
        "        print(f\"Skipping {name}: Missing file(s)\")\n",
        "        continue\n",
        "\n",
        "    with open(pred_file) as f:\n",
        "        pred_json = json.load(f)\n",
        "    with open(gt_file) as f:\n",
        "        gt_entries = json.load(f)\n",
        "\n",
        "    pred_entries = list(pred_json.values())[0] if isinstance(pred_json, dict) else pred_json\n",
        "    if isinstance(pred_entries[0], str):\n",
        "        pred_entries = [json.loads(p.replace(\"'\", '\"')) for p in pred_entries]\n",
        "\n",
        "    used_pred_indices = set()\n",
        "    final_output = []\n",
        "\n",
        "    for gt in gt_entries:\n",
        "        gt_box = gt[\"Coordinate\"]\n",
        "        gt_text = gt[\"Field value\"].strip()\n",
        "        field_name = gt.get(\"Field name\", \"\")\n",
        "\n",
        "        best_match, best_score, best_idx, best_box = \"\", 0, -1, None\n",
        "\n",
        "        for i, pred in enumerate(pred_entries):\n",
        "            if i in used_pred_indices:\n",
        "                continue\n",
        "            pred_box, pred_text = pred[\"box\"], pred[\"text\"]\n",
        "\n",
        "            if iou(gt_box, pred_box) > 0.3:\n",
        "                sim = similarity(gt_text.lower(), pred_text.strip().lower())\n",
        "                if sim > best_score:\n",
        "                    best_score = sim\n",
        "                    best_match = pred_text.strip()\n",
        "                    best_idx = i\n",
        "                    best_box = pred_box\n",
        "\n",
        "        if best_idx != -1:\n",
        "            used_pred_indices.add(best_idx)\n",
        "            cleaned_text = postprocess(field_name, best_match)\n",
        "            if cleaned_text:\n",
        "                final_output.append({\n",
        "                    \"text\": cleaned_text,\n",
        "                    \"bbox\": pred_entries[best_idx][\"box\"]\n",
        "                })\n",
        "\n",
        "    out_path = os.path.join(output_dir, name + \".json\")\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(final_output, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"✅ Saved: {out_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpxMMzZoHK4s",
        "outputId": "ea0e5c3d-4b88-4b3b-af17-494d152034c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_1.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_10.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_100.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_101.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_102.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_103.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_104.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_105.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_106.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_108.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_11.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_110.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_111.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_113.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_114.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_115.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_116.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_117.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_118.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_119.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_12.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_120.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_121.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_122.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_123.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_124.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_125.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_126.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_128.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_129.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_13.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_130.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_131.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_132.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_133.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_134.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_135.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_136.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_137.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_138.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_139.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_14.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_140.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_141.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_142.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_143.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_144.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_145.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_146.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_147.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_148.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_149.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_15.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_150.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_151.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_152.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_153.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_154.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_155.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_156.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_158.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_16.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_161.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_162.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_163.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_164.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_165.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_168.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_169.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_17.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_170.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_171.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_172.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_173.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/MIT_174.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_810.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_811.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_812.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_813.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_814.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_815.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_816.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_817.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_818.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_819.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_820.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_821.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_822.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_823.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_824.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_825.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_826.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_827.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_828.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_829.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_830.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_831.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_832.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_833.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_834.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_835.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_836.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_837.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_838.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_839.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_840.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_845.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_846.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_847.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_849.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_850.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_851.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_853.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_854.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_856.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_857.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_859.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_861.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_862.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_863.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_865.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_866.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_868.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_869.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_870.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_871.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_872.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_873.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_874.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_875.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_876.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_878.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_879.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_880.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_881.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_883.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_886.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_887.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_888.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_895.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_896.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_898.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_899.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_900.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_901.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_902.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_903.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_904.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_905.json\n",
            "✅ Saved: /content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS/VIT_906.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textblob pyspellchecker\n",
        "!python -m textblob.download_corpora\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uMB1OL_2s4x",
        "outputId": "442c32eb-f7c1-431a-a04a-57a3b4ce3dd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.8.2-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.11/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (4.67.1)\n",
            "Downloading pyspellchecker-0.8.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.8.2\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from difflib import SequenceMatcher\n",
        "from jiwer import wer, cer\n",
        "from glob import glob\n",
        "\n",
        "# --- Utility Functions ---\n",
        "def iou(boxA, boxB):\n",
        "    xA = max(boxA[0], boxB[0])\n",
        "    yA = max(boxA[1], boxB[1])\n",
        "    xB = min(boxA[2], boxB[2])\n",
        "    yB = min(boxA[3], boxB[3])\n",
        "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
        "    if interArea == 0:\n",
        "        return 0.0\n",
        "    areaA = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
        "    areaB = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
        "    return interArea / float(areaA + areaB - interArea)\n",
        "\n",
        "def similarity(a, b):\n",
        "    return SequenceMatcher(None, a, b).ratio()\n",
        "\n",
        "# --- Paths ---\n",
        "#pred_dir = \"/content/drive/MyDrive/Dehaldo/OCR_OUTPUTS/\"\n",
        "pred_dir = \"/content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS\"\n",
        "gt_dir = \"/content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/LABELS_750\"\n",
        "\n",
        "# Get all image names\n",
        "image_names = sorted([os.path.basename(f).replace(\".json\", \"\") for f in glob(os.path.join(gt_dir, \"*.json\"))])\n",
        "n_total = len(image_names)\n",
        "\n",
        "# First and last 10% of images\n",
        "first_10_percent = image_names[:int(n_total * 0.1)]\n",
        "last_10_percent = image_names[int(n_total * 0.9):]\n",
        "\n",
        "# --- Initialize Metrics ---\n",
        "total_exact_matches = 0\n",
        "total_fields = 0\n",
        "total_doc_matches = 0\n",
        "all_gt_texts = []\n",
        "all_pred_texts = []\n",
        "similarity_sum = 0\n",
        "similarity_count = 0\n",
        "cer_per_image = {}\n",
        "\n",
        "# --- Process First 10% and Last 10% of Images ---\n",
        "for name in first_10_percent + last_10_percent:\n",
        "    pred_file = os.path.join(pred_dir, name + \".json\")\n",
        "    gt_file = os.path.join(gt_dir, name + \".json\")\n",
        "\n",
        "    if not os.path.exists(pred_file) or not os.path.exists(gt_file):\n",
        "        print(f\"Skipping {name}: Missing file(s)\")\n",
        "        continue\n",
        "\n",
        "    with open(pred_file) as f:\n",
        "        pred_json = json.load(f)\n",
        "    with open(gt_file) as f:\n",
        "        gt_entries = json.load(f)\n",
        "\n",
        "    # Extract predictions (TrOCR format)\n",
        "    pred_entries = list(pred_json.values())[0] if isinstance(pred_json, dict) else pred_json\n",
        "\n",
        "    if isinstance(pred_entries[0], str):  # If stringified dicts\n",
        "        pred_entries = [json.loads(p.replace(\"'\", '\"')) for p in pred_entries]\n",
        "\n",
        "    matched, used_pred_indices = [], set()\n",
        "    gt_texts, pred_texts = [], []\n",
        "    exact_matches = 0\n",
        "\n",
        "    for gt in gt_entries:\n",
        "        gt_box = gt[\"Coordinate\"]\n",
        "        gt_text = gt[\"Field value\"]\n",
        "        best_match, best_score, best_idx = \"\", 0, -1\n",
        "\n",
        "        for i, pred in enumerate(pred_entries):\n",
        "            if i in used_pred_indices:\n",
        "                continue\n",
        "            pred_box, pred_text = pred[\"bbox\"], pred[\"text\"]\n",
        "\n",
        "            if iou(gt_box, pred_box) > 0.3:\n",
        "                sim = similarity(gt_text.strip().lower(), pred_text.strip().lower())\n",
        "                if sim > best_score:\n",
        "                    best_score, best_match, best_idx = sim, pred_text, i\n",
        "\n",
        "        gt_clean = gt_text.strip().lower()\n",
        "        if best_idx != -1:\n",
        "            used_pred_indices.add(best_idx)\n",
        "            pred_clean = best_match.strip().lower()\n",
        "            gt_texts.append(gt_clean)\n",
        "            pred_texts.append(pred_clean)\n",
        "            similarity_sum += similarity(gt_clean, pred_clean)\n",
        "            similarity_count += 1\n",
        "            if gt_clean == pred_clean:\n",
        "                exact_matches += 1\n",
        "        else:\n",
        "            gt_texts.append(gt_clean)\n",
        "            pred_texts.append(\"\")\n",
        "            similarity_sum += 0.0\n",
        "            similarity_count += 1\n",
        "\n",
        "    # Accumulate metrics\n",
        "    total_exact_matches += exact_matches\n",
        "    total_fields += len(gt_entries)\n",
        "    all_gt_texts.extend(gt_texts)\n",
        "    all_pred_texts.extend(pred_texts)\n",
        "    if exact_matches == len(gt_entries):\n",
        "        total_doc_matches += 1\n",
        "\n",
        "    # Compute and store per-image CER\n",
        "    image_cer = cer(gt_texts, pred_texts)\n",
        "    cer_per_image[name] = image_cer\n",
        "\n",
        "    print(f\"[{name}] Exact Match: {exact_matches}/{len(gt_entries)}  CER: {image_cer:.3f}\")\n",
        "\n",
        "# --- Final Metrics ---\n",
        "print(\"\\n========== Overall Evaluation ==========\")\n",
        "print(f\"Total Images Evaluated       : {len(cer_per_image)}\")\n",
        "print(f\"Total Fields                 : {total_fields}\")\n",
        "print(f\"Total Exact Text Matches     : {total_exact_matches}\")\n",
        "print(f\"Text Field Accuracy          : {total_exact_matches / total_fields:.3f}\" if total_fields else \"N/A\")\n",
        "print(f\"Document-Level Accuracy      : {total_doc_matches / len(cer_per_image):.3f}\" if cer_per_image else \"N/A\")\n",
        "print(f\"Word Error Rate (WER)        : {wer(all_gt_texts, all_pred_texts):.3f}\")\n",
        "print(f\"Character Error Rate (CER)   : {cer(all_gt_texts, all_pred_texts):.3f}\")\n",
        "print(f\"Average Text Similarity      : {similarity_sum / similarity_count:.3f}\" if similarity_count else \"N/A\")\n",
        "\n",
        "# --- Top 5 images with lowest CER ---\n",
        "sorted_cer = sorted(cer_per_image.items(), key=lambda x: x[1])\n",
        "print(\"\\nTop 5 Images with Best CER:\")\n",
        "for name, c in sorted_cer[:5]:\n",
        "    print(f\"{name}: CER = {c:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OuzCSLHH285",
        "outputId": "628b221f-d398-419a-f6e1-1bde13ef958c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MIT_1] Exact Match: 9/20  CER: 0.128\n",
            "[MIT_10] Exact Match: 5/20  CER: 0.244\n",
            "[MIT_100] Exact Match: 7/20  CER: 0.155\n",
            "[MIT_101] Exact Match: 6/20  CER: 0.214\n",
            "[MIT_102] Exact Match: 4/20  CER: 0.235\n",
            "[MIT_103] Exact Match: 3/20  CER: 0.345\n",
            "[MIT_104] Exact Match: 4/20  CER: 0.276\n",
            "[MIT_105] Exact Match: 4/20  CER: 0.346\n",
            "[MIT_106] Exact Match: 9/20  CER: 0.106\n",
            "[MIT_108] Exact Match: 4/20  CER: 0.338\n",
            "[MIT_11] Exact Match: 4/20  CER: 0.323\n",
            "[MIT_110] Exact Match: 5/19  CER: 0.305\n",
            "[MIT_111] Exact Match: 9/19  CER: 0.188\n",
            "[MIT_113] Exact Match: 1/17  CER: 0.741\n",
            "[MIT_114] Exact Match: 1/20  CER: 0.573\n",
            "[MIT_115] Exact Match: 2/20  CER: 0.340\n",
            "[MIT_116] Exact Match: 5/20  CER: 0.297\n",
            "[MIT_117] Exact Match: 9/20  CER: 0.211\n",
            "[MIT_118] Exact Match: 6/21  CER: 0.262\n",
            "[MIT_119] Exact Match: 10/20  CER: 0.121\n",
            "[MIT_12] Exact Match: 5/20  CER: 0.231\n",
            "[MIT_120] Exact Match: 8/20  CER: 0.151\n",
            "[MIT_121] Exact Match: 4/20  CER: 0.224\n",
            "[MIT_122] Exact Match: 8/21  CER: 0.202\n",
            "[MIT_123] Exact Match: 10/20  CER: 0.198\n",
            "[MIT_124] Exact Match: 7/20  CER: 0.217\n",
            "[MIT_125] Exact Match: 6/20  CER: 0.155\n",
            "[MIT_126] Exact Match: 5/20  CER: 0.266\n",
            "[MIT_128] Exact Match: 6/20  CER: 0.255\n",
            "[MIT_129] Exact Match: 8/20  CER: 0.147\n",
            "[MIT_13] Exact Match: 11/21  CER: 0.122\n",
            "[MIT_130] Exact Match: 6/19  CER: 0.206\n",
            "[MIT_131] Exact Match: 6/20  CER: 0.148\n",
            "[MIT_132] Exact Match: 6/20  CER: 0.195\n",
            "[MIT_133] Exact Match: 6/20  CER: 0.161\n",
            "[MIT_134] Exact Match: 7/20  CER: 0.310\n",
            "[MIT_135] Exact Match: 9/20  CER: 0.122\n",
            "[MIT_136] Exact Match: 5/20  CER: 0.201\n",
            "[MIT_137] Exact Match: 8/20  CER: 0.138\n",
            "[MIT_138] Exact Match: 6/21  CER: 0.186\n",
            "[MIT_139] Exact Match: 8/20  CER: 0.198\n",
            "[MIT_14] Exact Match: 14/20  CER: 0.117\n",
            "[MIT_140] Exact Match: 6/20  CER: 0.265\n",
            "[MIT_141] Exact Match: 7/20  CER: 0.148\n",
            "[MIT_142] Exact Match: 5/20  CER: 0.298\n",
            "[MIT_143] Exact Match: 3/21  CER: 0.214\n",
            "[MIT_144] Exact Match: 8/20  CER: 0.188\n",
            "[MIT_145] Exact Match: 5/20  CER: 0.276\n",
            "[MIT_146] Exact Match: 7/20  CER: 0.278\n",
            "[MIT_147] Exact Match: 8/20  CER: 0.142\n",
            "[MIT_148] Exact Match: 4/20  CER: 0.317\n",
            "[MIT_149] Exact Match: 9/20  CER: 0.152\n",
            "[MIT_15] Exact Match: 7/20  CER: 0.225\n",
            "[MIT_150] Exact Match: 8/20  CER: 0.177\n",
            "[MIT_151] Exact Match: 9/20  CER: 0.161\n",
            "[MIT_152] Exact Match: 6/20  CER: 0.175\n",
            "[MIT_153] Exact Match: 8/19  CER: 0.114\n",
            "[MIT_154] Exact Match: 7/20  CER: 0.155\n",
            "[MIT_155] Exact Match: 9/20  CER: 0.115\n",
            "[MIT_156] Exact Match: 9/20  CER: 0.094\n",
            "[MIT_158] Exact Match: 7/20  CER: 0.184\n",
            "[MIT_16] Exact Match: 12/20  CER: 0.205\n",
            "[MIT_161] Exact Match: 10/20  CER: 0.130\n",
            "[MIT_162] Exact Match: 9/20  CER: 0.156\n",
            "[MIT_163] Exact Match: 7/21  CER: 0.213\n",
            "[MIT_164] Exact Match: 11/20  CER: 0.125\n",
            "[MIT_165] Exact Match: 8/20  CER: 0.156\n",
            "[MIT_168] Exact Match: 10/20  CER: 0.085\n",
            "[MIT_169] Exact Match: 9/20  CER: 0.087\n",
            "[MIT_17] Exact Match: 8/20  CER: 0.133\n",
            "[MIT_170] Exact Match: 9/20  CER: 0.186\n",
            "[MIT_171] Exact Match: 9/20  CER: 0.128\n",
            "[MIT_172] Exact Match: 8/20  CER: 0.144\n",
            "[MIT_173] Exact Match: 8/20  CER: 0.103\n",
            "[MIT_174] Exact Match: 8/21  CER: 0.237\n",
            "[VIT_810] Exact Match: 5/20  CER: 0.175\n",
            "[VIT_811] Exact Match: 5/20  CER: 0.185\n",
            "[VIT_812] Exact Match: 5/20  CER: 0.172\n",
            "[VIT_813] Exact Match: 3/20  CER: 0.168\n",
            "[VIT_814] Exact Match: 4/21  CER: 0.220\n",
            "[VIT_815] Exact Match: 8/21  CER: 0.182\n",
            "[VIT_816] Exact Match: 5/20  CER: 0.223\n",
            "[VIT_817] Exact Match: 6/19  CER: 0.187\n",
            "[VIT_818] Exact Match: 7/19  CER: 0.141\n",
            "[VIT_819] Exact Match: 7/20  CER: 0.221\n",
            "[VIT_820] Exact Match: 4/20  CER: 0.214\n",
            "[VIT_821] Exact Match: 6/20  CER: 0.229\n",
            "[VIT_822] Exact Match: 6/20  CER: 0.241\n",
            "[VIT_823] Exact Match: 5/20  CER: 0.302\n",
            "[VIT_824] Exact Match: 7/20  CER: 0.248\n",
            "[VIT_825] Exact Match: 8/20  CER: 0.176\n",
            "[VIT_826] Exact Match: 6/20  CER: 0.263\n",
            "[VIT_827] Exact Match: 9/21  CER: 0.193\n",
            "[VIT_828] Exact Match: 4/20  CER: 0.211\n",
            "[VIT_829] Exact Match: 7/21  CER: 0.220\n",
            "[VIT_830] Exact Match: 7/20  CER: 0.189\n",
            "[VIT_831] Exact Match: 8/19  CER: 0.164\n",
            "[VIT_832] Exact Match: 5/20  CER: 0.160\n",
            "[VIT_833] Exact Match: 7/20  CER: 0.159\n",
            "[VIT_834] Exact Match: 5/20  CER: 0.276\n",
            "[VIT_835] Exact Match: 6/20  CER: 0.166\n",
            "[VIT_836] Exact Match: 7/20  CER: 0.135\n",
            "[VIT_837] Exact Match: 7/20  CER: 0.188\n",
            "[VIT_838] Exact Match: 6/20  CER: 0.220\n",
            "[VIT_839] Exact Match: 5/20  CER: 0.278\n",
            "[VIT_840] Exact Match: 8/20  CER: 0.211\n",
            "[VIT_845] Exact Match: 4/20  CER: 0.217\n",
            "[VIT_846] Exact Match: 5/20  CER: 0.189\n",
            "[VIT_847] Exact Match: 10/20  CER: 0.117\n",
            "[VIT_849] Exact Match: 7/20  CER: 0.215\n",
            "[VIT_850] Exact Match: 7/20  CER: 0.217\n",
            "[VIT_851] Exact Match: 5/20  CER: 0.167\n",
            "[VIT_853] Exact Match: 8/21  CER: 0.190\n",
            "[VIT_854] Exact Match: 5/20  CER: 0.287\n",
            "[VIT_856] Exact Match: 9/20  CER: 0.133\n",
            "[VIT_857] Exact Match: 9/20  CER: 0.107\n",
            "[VIT_859] Exact Match: 7/20  CER: 0.198\n",
            "[VIT_861] Exact Match: 7/20  CER: 0.181\n",
            "[VIT_862] Exact Match: 5/19  CER: 0.171\n",
            "[VIT_863] Exact Match: 6/20  CER: 0.155\n",
            "[VIT_865] Exact Match: 9/21  CER: 0.168\n",
            "[VIT_866] Exact Match: 8/20  CER: 0.205\n",
            "[VIT_868] Exact Match: 8/20  CER: 0.123\n",
            "[VIT_869] Exact Match: 13/20  CER: 0.071\n",
            "[VIT_870] Exact Match: 6/20  CER: 0.190\n",
            "[VIT_871] Exact Match: 7/20  CER: 0.209\n",
            "[VIT_872] Exact Match: 5/20  CER: 0.196\n",
            "[VIT_873] Exact Match: 10/20  CER: 0.116\n",
            "[VIT_874] Exact Match: 4/20  CER: 0.197\n",
            "[VIT_875] Exact Match: 5/20  CER: 0.167\n",
            "[VIT_876] Exact Match: 6/19  CER: 0.115\n",
            "[VIT_878] Exact Match: 6/20  CER: 0.236\n",
            "[VIT_879] Exact Match: 5/20  CER: 0.162\n",
            "[VIT_880] Exact Match: 6/20  CER: 0.174\n",
            "[VIT_881] Exact Match: 9/20  CER: 0.135\n",
            "[VIT_883] Exact Match: 5/20  CER: 0.248\n",
            "[VIT_886] Exact Match: 7/20  CER: 0.180\n",
            "[VIT_887] Exact Match: 11/21  CER: 0.168\n",
            "[VIT_888] Exact Match: 10/20  CER: 0.164\n",
            "[VIT_895] Exact Match: 5/19  CER: 0.190\n",
            "[VIT_896] Exact Match: 4/20  CER: 0.262\n",
            "[VIT_898] Exact Match: 4/20  CER: 0.264\n",
            "[VIT_899] Exact Match: 2/20  CER: 0.279\n",
            "[VIT_900] Exact Match: 4/20  CER: 0.388\n",
            "[VIT_901] Exact Match: 10/20  CER: 0.070\n",
            "[VIT_902] Exact Match: 8/20  CER: 0.245\n",
            "[VIT_903] Exact Match: 12/20  CER: 0.086\n",
            "[VIT_904] Exact Match: 8/20  CER: 0.142\n",
            "[VIT_905] Exact Match: 10/21  CER: 0.064\n",
            "[VIT_906] Exact Match: 7/21  CER: 0.130\n",
            "\n",
            "========== Overall Evaluation ==========\n",
            "Total Images Evaluated       : 150\n",
            "Total Fields                 : 3003\n",
            "Total Exact Text Matches     : 1020\n",
            "Text Field Accuracy          : 0.340\n",
            "Document-Level Accuracy      : 0.000\n",
            "Word Error Rate (WER)        : 0.624\n",
            "Character Error Rate (CER)   : 0.199\n",
            "Average Text Similarity      : 0.858\n",
            "\n",
            "Top 5 Images with Best CER:\n",
            "VIT_905: CER = 0.064\n",
            "VIT_901: CER = 0.070\n",
            "VIT_869: CER = 0.071\n",
            "MIT_168: CER = 0.085\n",
            "VIT_903: CER = 0.086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from difflib import SequenceMatcher\n",
        "from jiwer import wer, cer\n",
        "from glob import glob\n",
        "\n",
        "# --- Utility Functions ---\n",
        "def iou(boxA, boxB):\n",
        "    xA = max(boxA[0], boxB[0])\n",
        "    yA = max(boxA[1], boxB[1])\n",
        "    xB = min(boxA[2], boxB[2])\n",
        "    yB = min(boxA[3], boxB[3])\n",
        "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
        "    if interArea == 0:\n",
        "        return 0.0\n",
        "    areaA = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
        "    areaB = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
        "    return interArea / float(areaA + areaB - interArea)\n",
        "\n",
        "def similarity(a, b):\n",
        "    return SequenceMatcher(None, a, b).ratio()\n",
        "\n",
        "# --- Paths ---\n",
        "pred_dir = \"/content/drive/MyDrive/Dehaldo/POSTPROCESSED_OUTPUTS\"\n",
        "gt_dir = \"/content/drive/MyDrive/Dehaldo/DEHADO-AI_TRAINING_DATASET_unzipped/DEHADO-AI_TRAINING_DATASET/LABELS_750\"\n",
        "\n",
        "# Get all image names\n",
        "image_names = sorted([os.path.basename(f).replace(\".json\", \"\") for f in glob(os.path.join(gt_dir, \"*.json\"))])\n",
        "n_total = len(image_names)\n",
        "\n",
        "# First and last 10% of images\n",
        "first_10_percent = image_names[:int(n_total * 0.1)]\n",
        "last_10_percent = image_names[int(n_total * 0.9):]\n",
        "\n",
        "# --- Initialize Metrics ---\n",
        "total_exact_matches = 0\n",
        "total_fields = 0\n",
        "total_doc_matches = 0\n",
        "all_gt_texts = []\n",
        "all_pred_texts = []\n",
        "similarity_sum = 0\n",
        "similarity_count = 0\n",
        "cer_per_image = {}\n",
        "\n",
        "# --- Process Images ---\n",
        "for name in first_10_percent + last_10_percent:\n",
        "    pred_file = os.path.join(pred_dir, name + \".json\")\n",
        "    gt_file = os.path.join(gt_dir, name + \".json\")\n",
        "\n",
        "    if not os.path.exists(pred_file) or not os.path.exists(gt_file):\n",
        "        print(f\"Skipping {name}: Missing file(s)\")\n",
        "        continue\n",
        "\n",
        "    with open(pred_file) as f:\n",
        "        pred_json = json.load(f)\n",
        "    with open(gt_file) as f:\n",
        "        gt_entries = json.load(f)\n",
        "\n",
        "    # Extract predictions (TrOCR format)\n",
        "    pred_entries = list(pred_json.values())[0] if isinstance(pred_json, dict) else pred_json\n",
        "    if isinstance(pred_entries[0], str):\n",
        "        pred_entries = [json.loads(p.replace(\"'\", '\"')) for p in pred_entries]\n",
        "\n",
        "    matched, used_pred_indices = [], set()\n",
        "    gt_texts, pred_texts = [], []\n",
        "    exact_matches = 0\n",
        "\n",
        "    for gt in gt_entries:\n",
        "        gt_box = gt[\"Coordinate\"]\n",
        "        gt_text = gt[\"Field value\"]\n",
        "        best_match, best_score, best_idx = \"\", 0, -1\n",
        "\n",
        "        for i, pred in enumerate(pred_entries):\n",
        "            if i in used_pred_indices:\n",
        "                continue\n",
        "            pred_box, pred_text = pred[\"bbox\"], pred[\"text\"]\n",
        "\n",
        "            if iou(gt_box, pred_box) > 0.3:\n",
        "                sim = similarity(gt_text.strip().lower(), pred_text.strip().lower())\n",
        "                if sim > best_score:\n",
        "                    best_score, best_match, best_idx = sim, pred_text, i\n",
        "\n",
        "        gt_clean = gt_text.strip().lower()\n",
        "        if best_idx != -1:\n",
        "            used_pred_indices.add(best_idx)\n",
        "            pred_clean = best_match.strip().lower()\n",
        "            gt_texts.append(gt_clean)\n",
        "            pred_texts.append(pred_clean)\n",
        "            similarity_sum += similarity(gt_clean, pred_clean)\n",
        "            similarity_count += 1\n",
        "            if gt_clean == pred_clean:\n",
        "                exact_matches += 1\n",
        "        else:\n",
        "            gt_texts.append(gt_clean)\n",
        "            pred_texts.append(\"\")\n",
        "            similarity_sum += 0.0\n",
        "            similarity_count += 1\n",
        "\n",
        "    # Accumulate metrics\n",
        "    total_exact_matches += exact_matches\n",
        "    total_fields += len(gt_entries)\n",
        "    all_gt_texts.extend(gt_texts)\n",
        "    all_pred_texts.extend(pred_texts)\n",
        "\n",
        "    match_percentage = exact_matches / len(gt_entries)\n",
        "    if match_percentage == 1:\n",
        "        total_doc_matches += 1\n",
        "\n",
        "    # Compute and store per-image CER\n",
        "    image_cer = cer(gt_texts, pred_texts)\n",
        "    cer_per_image[name] = image_cer\n",
        "\n",
        "    print(f\"[{name}] Exact Match: {exact_matches}/{len(gt_entries)}  CER: {image_cer*100:.2f}%\")\n",
        "\n",
        "# --- Final Metrics ---\n",
        "wer_score = wer(all_gt_texts, all_pred_texts)\n",
        "cer_score = cer(all_gt_texts, all_pred_texts)\n",
        "field_acc = total_exact_matches / total_fields if total_fields else 0\n",
        "doc_acc = total_doc_matches / len(cer_per_image) if cer_per_image else 0\n",
        "avg_sim = similarity_sum / similarity_count if similarity_count else 0\n",
        "\n",
        "print(\"\\n========== Overall Evaluation ==========\")\n",
        "print(f\"Total Images Evaluated       : {len(cer_per_image)}\")\n",
        "print(f\"Total Fields                 : {total_fields}\")\n",
        "print(f\"Total Exact Text Matches     : {total_exact_matches}\")\n",
        "print(f\"Text Field Accuracy          : {field_acc * 100:.2f}%\")\n",
        "print(f\"Document-Level Accuracy      : {doc_acc * 100:.2f}%\")\n",
        "print(f\"Word Error Rate (WER)        : {wer_score * 100:.2f}%\")\n",
        "print(f\"Character Error Rate (CER)   : {cer_score * 100:.2f}%\")\n",
        "print(f\"Average Text Similarity      : {avg_sim * 100:.2f}%\")\n",
        "\n",
        "# --- Final Score ---\n",
        "final_score = (0.35 * (100 - wer_score * 100) +\n",
        "               0.35 * (100 - cer_score * 100) +\n",
        "               0.15 * (field_acc * 100) +\n",
        "               0.15 * (doc_acc * 100))\n",
        "\n",
        "print(f\"\\nFinal Composite Score        : {final_score:.2f}/100\")\n",
        "\n",
        "# --- Top 5 images with best CER ---\n",
        "sorted_cer = sorted(cer_per_image.items(), key=lambda x: x[1])\n",
        "print(\"\\nTop 5 Images with Best CER:\")\n",
        "for name, c in sorted_cer[:5]:\n",
        "    print(f\"{name}: CER = {c * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qC6BeEc2Rkqd",
        "outputId": "ec9d7abf-0c2c-4300-e8e1-e17b69f11b94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MIT_1] Exact Match: 9/20  CER: 12.77%\n",
            "[MIT_10] Exact Match: 5/20  CER: 24.42%\n",
            "[MIT_100] Exact Match: 7/20  CER: 15.46%\n",
            "[MIT_101] Exact Match: 6/20  CER: 21.41%\n",
            "[MIT_102] Exact Match: 4/20  CER: 23.51%\n",
            "[MIT_103] Exact Match: 3/20  CER: 34.49%\n",
            "[MIT_104] Exact Match: 4/20  CER: 27.63%\n",
            "[MIT_105] Exact Match: 4/20  CER: 34.64%\n",
            "[MIT_106] Exact Match: 9/20  CER: 10.56%\n",
            "[MIT_108] Exact Match: 4/20  CER: 33.80%\n",
            "[MIT_11] Exact Match: 4/20  CER: 32.31%\n",
            "[MIT_110] Exact Match: 5/19  CER: 30.49%\n",
            "[MIT_111] Exact Match: 9/19  CER: 18.75%\n",
            "[MIT_113] Exact Match: 1/17  CER: 74.15%\n",
            "[MIT_114] Exact Match: 1/20  CER: 57.27%\n",
            "[MIT_115] Exact Match: 2/20  CER: 34.00%\n",
            "[MIT_116] Exact Match: 5/20  CER: 29.67%\n",
            "[MIT_117] Exact Match: 9/20  CER: 21.07%\n",
            "[MIT_118] Exact Match: 6/21  CER: 26.18%\n",
            "[MIT_119] Exact Match: 10/20  CER: 12.07%\n",
            "[MIT_12] Exact Match: 5/20  CER: 23.10%\n",
            "[MIT_120] Exact Match: 8/20  CER: 15.08%\n",
            "[MIT_121] Exact Match: 4/20  CER: 22.39%\n",
            "[MIT_122] Exact Match: 8/21  CER: 20.24%\n",
            "[MIT_123] Exact Match: 10/20  CER: 19.81%\n",
            "[MIT_124] Exact Match: 7/20  CER: 21.74%\n",
            "[MIT_125] Exact Match: 6/20  CER: 15.51%\n",
            "[MIT_126] Exact Match: 5/20  CER: 26.60%\n",
            "[MIT_128] Exact Match: 6/20  CER: 25.46%\n",
            "[MIT_129] Exact Match: 8/20  CER: 14.67%\n",
            "[MIT_13] Exact Match: 11/21  CER: 12.18%\n",
            "[MIT_130] Exact Match: 6/19  CER: 20.64%\n",
            "[MIT_131] Exact Match: 6/20  CER: 14.80%\n",
            "[MIT_132] Exact Match: 6/20  CER: 19.47%\n",
            "[MIT_133] Exact Match: 6/20  CER: 16.11%\n",
            "[MIT_134] Exact Match: 7/20  CER: 31.01%\n",
            "[MIT_135] Exact Match: 9/20  CER: 12.23%\n",
            "[MIT_136] Exact Match: 5/20  CER: 20.06%\n",
            "[MIT_137] Exact Match: 8/20  CER: 13.77%\n",
            "[MIT_138] Exact Match: 6/21  CER: 18.55%\n",
            "[MIT_139] Exact Match: 8/20  CER: 19.82%\n",
            "[MIT_14] Exact Match: 14/20  CER: 11.67%\n",
            "[MIT_140] Exact Match: 6/20  CER: 26.53%\n",
            "[MIT_141] Exact Match: 7/20  CER: 14.76%\n",
            "[MIT_142] Exact Match: 5/20  CER: 29.79%\n",
            "[MIT_143] Exact Match: 3/21  CER: 21.36%\n",
            "[MIT_144] Exact Match: 8/20  CER: 18.79%\n",
            "[MIT_145] Exact Match: 5/20  CER: 27.56%\n",
            "[MIT_146] Exact Match: 7/20  CER: 27.76%\n",
            "[MIT_147] Exact Match: 8/20  CER: 14.20%\n",
            "[MIT_148] Exact Match: 4/20  CER: 31.72%\n",
            "[MIT_149] Exact Match: 9/20  CER: 15.22%\n",
            "[MIT_15] Exact Match: 7/20  CER: 22.50%\n",
            "[MIT_150] Exact Match: 8/20  CER: 17.70%\n",
            "[MIT_151] Exact Match: 9/20  CER: 16.05%\n",
            "[MIT_152] Exact Match: 6/20  CER: 17.48%\n",
            "[MIT_153] Exact Match: 8/19  CER: 11.42%\n",
            "[MIT_154] Exact Match: 7/20  CER: 15.48%\n",
            "[MIT_155] Exact Match: 9/20  CER: 11.50%\n",
            "[MIT_156] Exact Match: 9/20  CER: 9.40%\n",
            "[MIT_158] Exact Match: 7/20  CER: 18.37%\n",
            "[MIT_16] Exact Match: 12/20  CER: 20.46%\n",
            "[MIT_161] Exact Match: 10/20  CER: 12.97%\n",
            "[MIT_162] Exact Match: 9/20  CER: 15.61%\n",
            "[MIT_163] Exact Match: 7/21  CER: 21.27%\n",
            "[MIT_164] Exact Match: 11/20  CER: 12.54%\n",
            "[MIT_165] Exact Match: 8/20  CER: 15.59%\n",
            "[MIT_168] Exact Match: 10/20  CER: 8.53%\n",
            "[MIT_169] Exact Match: 9/20  CER: 8.68%\n",
            "[MIT_17] Exact Match: 8/20  CER: 13.31%\n",
            "[MIT_170] Exact Match: 9/20  CER: 18.58%\n",
            "[MIT_171] Exact Match: 9/20  CER: 12.78%\n",
            "[MIT_172] Exact Match: 8/20  CER: 14.42%\n",
            "[MIT_173] Exact Match: 8/20  CER: 10.30%\n",
            "[MIT_174] Exact Match: 8/21  CER: 23.70%\n",
            "[VIT_810] Exact Match: 5/20  CER: 17.48%\n",
            "[VIT_811] Exact Match: 5/20  CER: 18.53%\n",
            "[VIT_812] Exact Match: 5/20  CER: 17.23%\n",
            "[VIT_813] Exact Match: 3/20  CER: 16.82%\n",
            "[VIT_814] Exact Match: 4/21  CER: 21.95%\n",
            "[VIT_815] Exact Match: 8/21  CER: 18.15%\n",
            "[VIT_816] Exact Match: 5/20  CER: 22.26%\n",
            "[VIT_817] Exact Match: 6/19  CER: 18.67%\n",
            "[VIT_818] Exact Match: 7/19  CER: 14.10%\n",
            "[VIT_819] Exact Match: 7/20  CER: 22.07%\n",
            "[VIT_820] Exact Match: 4/20  CER: 21.41%\n",
            "[VIT_821] Exact Match: 6/20  CER: 22.87%\n",
            "[VIT_822] Exact Match: 6/20  CER: 24.14%\n",
            "[VIT_823] Exact Match: 5/20  CER: 30.25%\n",
            "[VIT_824] Exact Match: 7/20  CER: 24.84%\n",
            "[VIT_825] Exact Match: 8/20  CER: 17.57%\n",
            "[VIT_826] Exact Match: 6/20  CER: 26.35%\n",
            "[VIT_827] Exact Match: 9/21  CER: 19.34%\n",
            "[VIT_828] Exact Match: 4/20  CER: 21.10%\n",
            "[VIT_829] Exact Match: 7/21  CER: 22.04%\n",
            "[VIT_830] Exact Match: 7/20  CER: 18.89%\n",
            "[VIT_831] Exact Match: 8/19  CER: 16.45%\n",
            "[VIT_832] Exact Match: 5/20  CER: 16.01%\n",
            "[VIT_833] Exact Match: 7/20  CER: 15.91%\n",
            "[VIT_834] Exact Match: 5/20  CER: 27.57%\n",
            "[VIT_835] Exact Match: 6/20  CER: 16.61%\n",
            "[VIT_836] Exact Match: 7/20  CER: 13.46%\n",
            "[VIT_837] Exact Match: 7/20  CER: 18.81%\n",
            "[VIT_838] Exact Match: 6/20  CER: 22.03%\n",
            "[VIT_839] Exact Match: 5/20  CER: 27.81%\n",
            "[VIT_840] Exact Match: 8/20  CER: 21.07%\n",
            "[VIT_845] Exact Match: 4/20  CER: 21.70%\n",
            "[VIT_846] Exact Match: 5/20  CER: 18.94%\n",
            "[VIT_847] Exact Match: 10/20  CER: 11.75%\n",
            "[VIT_849] Exact Match: 7/20  CER: 21.50%\n",
            "[VIT_850] Exact Match: 7/20  CER: 21.68%\n",
            "[VIT_851] Exact Match: 5/20  CER: 16.67%\n",
            "[VIT_853] Exact Match: 8/21  CER: 19.03%\n",
            "[VIT_854] Exact Match: 5/20  CER: 28.71%\n",
            "[VIT_856] Exact Match: 9/20  CER: 13.27%\n",
            "[VIT_857] Exact Match: 9/20  CER: 10.70%\n",
            "[VIT_859] Exact Match: 7/20  CER: 19.76%\n",
            "[VIT_861] Exact Match: 7/20  CER: 18.12%\n",
            "[VIT_862] Exact Match: 5/19  CER: 17.11%\n",
            "[VIT_863] Exact Match: 6/20  CER: 15.48%\n",
            "[VIT_865] Exact Match: 9/21  CER: 16.82%\n",
            "[VIT_866] Exact Match: 8/20  CER: 20.47%\n",
            "[VIT_868] Exact Match: 8/20  CER: 12.34%\n",
            "[VIT_869] Exact Match: 13/20  CER: 7.06%\n",
            "[VIT_870] Exact Match: 6/20  CER: 19.02%\n",
            "[VIT_871] Exact Match: 7/20  CER: 20.95%\n",
            "[VIT_872] Exact Match: 5/20  CER: 19.59%\n",
            "[VIT_873] Exact Match: 10/20  CER: 11.55%\n",
            "[VIT_874] Exact Match: 4/20  CER: 19.69%\n",
            "[VIT_875] Exact Match: 5/20  CER: 16.67%\n",
            "[VIT_876] Exact Match: 6/19  CER: 11.54%\n",
            "[VIT_878] Exact Match: 6/20  CER: 23.57%\n",
            "[VIT_879] Exact Match: 5/20  CER: 16.21%\n",
            "[VIT_880] Exact Match: 6/20  CER: 17.43%\n",
            "[VIT_881] Exact Match: 9/20  CER: 13.46%\n",
            "[VIT_883] Exact Match: 5/20  CER: 24.83%\n",
            "[VIT_886] Exact Match: 7/20  CER: 17.98%\n",
            "[VIT_887] Exact Match: 11/21  CER: 16.76%\n",
            "[VIT_888] Exact Match: 10/20  CER: 16.35%\n",
            "[VIT_895] Exact Match: 5/19  CER: 19.00%\n",
            "[VIT_896] Exact Match: 4/20  CER: 26.21%\n",
            "[VIT_898] Exact Match: 4/20  CER: 26.36%\n",
            "[VIT_899] Exact Match: 2/20  CER: 27.90%\n",
            "[VIT_900] Exact Match: 4/20  CER: 38.80%\n",
            "[VIT_901] Exact Match: 10/20  CER: 6.98%\n",
            "[VIT_902] Exact Match: 8/20  CER: 24.52%\n",
            "[VIT_903] Exact Match: 12/20  CER: 8.62%\n",
            "[VIT_904] Exact Match: 8/20  CER: 14.19%\n",
            "[VIT_905] Exact Match: 10/21  CER: 6.40%\n",
            "[VIT_906] Exact Match: 7/21  CER: 13.03%\n",
            "\n",
            "========== Overall Evaluation ==========\n",
            "Total Images Evaluated       : 150\n",
            "Total Fields                 : 3003\n",
            "Total Exact Text Matches     : 1020\n",
            "Text Field Accuracy          : 33.97%\n",
            "Document-Level Accuracy      : 0.00%\n",
            "Word Error Rate (WER)        : 62.40%\n",
            "Character Error Rate (CER)   : 19.92%\n",
            "Average Text Similarity      : 85.85%\n",
            "\n",
            "Final Composite Score        : 46.28/100\n",
            "\n",
            "Top 5 Images with Best CER:\n",
            "VIT_905: CER = 6.40%\n",
            "VIT_901: CER = 6.98%\n",
            "VIT_869: CER = 7.06%\n",
            "MIT_168: CER = 8.53%\n",
            "VIT_903: CER = 8.62%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I7F-7nCBJvFl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}